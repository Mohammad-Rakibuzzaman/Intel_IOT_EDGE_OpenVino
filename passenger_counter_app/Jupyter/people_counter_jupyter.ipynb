{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MODEL=/opt/intel/openvino/deployment_tools/tools/model_downloader/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml\n",
    "%env DEVICE=CPU\n",
    "%env INPUT=Pedestrain_Detect_2_1_1.mp4\n",
    "%env PERF_COUNTS=False\n",
    "%env PROB_THRESHOLD=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"People Counter.\"\"\"\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit person to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import socket\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import logging as log\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from inference import Network\n",
    "import subprocess\n",
    "# MQTT server environment variables\n",
    "HOSTNAME = socket.gethostname()\n",
    "IPADDRESS = socket.gethostbyname(HOSTNAME)\n",
    "TOPIC = \"people_counter_python\"\n",
    "MQTT_HOST = IPADDRESS\n",
    "MQTT_PORT = 1884\n",
    "MQTT_KEEPALIVE_INTERVAL = 60\n",
    "\n",
    "CONFIG_FILE = '../resources/config.json'\n",
    "\n",
    "def performance_counts(perf_count):\n",
    "    \"\"\"\n",
    "    print information about layers of the model.\n",
    "\n",
    "    :param perf_count: Dictionary consists of status of the layers.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    print(\"{:<70} {:<15} {:<15} {:<15} {:<10}\".format('name', 'layer_type',\n",
    "                                                      'exec_type', 'status',\n",
    "                                                      'real_time, us'))\n",
    "    for layer, stats in perf_count.items():\n",
    "        print(\"{:<70} {:<15} {:<15} {:<15} {:<10}\".format(layer,\n",
    "                                                          stats['layer_type'],\n",
    "                                                          stats['exec_type'],\n",
    "                                                          stats['status'],\n",
    "                                                          stats['real_time']))\n",
    "\n",
    "\n",
    "def ssd_out(frame, result):\n",
    "    \"\"\"\n",
    "    Parse SSD output.\n",
    "\n",
    "    :param frame: frame from camera/video\n",
    "    :param result: list contains the data to parse ssd\n",
    "    :return: person count and frame\n",
    "    \"\"\"\n",
    "    current_count = 0\n",
    "    for obj in result[0][0]:\n",
    "        # Draw bounding box for object when it's probability is more than\n",
    "        #  the specified threshold\n",
    "        if obj[2] > prob_threshold:\n",
    "            xmin = int(obj[3] * initial_w)\n",
    "            ymin = int(obj[4] * initial_h)\n",
    "            xmax = int(obj[5] * initial_w)\n",
    "            ymax = int(obj[6] * initial_h)\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 55, 255), 1)\n",
    "            current_count = current_count + 1\n",
    "    return frame, current_count\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load the network and parse the SSD output.\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the MQTT server\n",
    "    client = mqtt.Client()\n",
    "    client.connect(MQTT_HOST, MQTT_PORT, MQTT_KEEPALIVE_INTERVAL)\n",
    "    client.subscribe(TOPIC)\n",
    "\n",
    "    #args = build_argparser().parse_args()\n",
    "\n",
    "    # Flag for the input image\n",
    "    single_image_mode = False\n",
    "\n",
    "\n",
    "    cur_request_id = 0\n",
    "    last_count = 0\n",
    "    total_count = 0\n",
    "    start_time = 0\n",
    "\n",
    "    # Initialise the class\n",
    "    infer_network = Network()\n",
    "    model = os.environ['MODEL']\n",
    "    device =  os.environ['DEVICE']\n",
    "    # Load the network to IE plugin to get shape of input layer\n",
    "    n, c, h, w = infer_network.load_model(model, device, 1, 1, cur_request_id)[1]\n",
    "\n",
    "        \n",
    "    assert os.path.isfile(CONFIG_FILE), \"{} file doesn't exist\".format(CONFIG_FILE)\n",
    "    config = json.loads(open(CONFIG_FILE).read())\n",
    "\n",
    "    for idx, item in enumerate(config['inputs']):\n",
    "        if item['video'].isdigit():\n",
    "            input_stream = int(item['video'])\n",
    "        elif [item['video'].endswith('.jpg') or item['video'].endswith('.bmp')] :\n",
    "            single_image_mode = True\n",
    "            input_stream = item['video']\n",
    "            \n",
    "        else:\n",
    "            input_stream = item['video']\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture(input_stream)\n",
    "\n",
    "\n",
    "    if input_stream:\n",
    "        cap.open(input_stream)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        log.error(\"ERROR! Unable to open video source\")\n",
    "    global initial_w, initial_h, prob_threshold\n",
    "    prob_threshold = float(os.environ['PROB_THRESHOLD'])\n",
    "    initial_w = cap.get(3)\n",
    "    initial_h = cap.get(4)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cmdstring = ('ffmpeg',\n",
    "                 '-y', '-r', '%d' %(fps), # overwrite, 60fps\n",
    "                 '-s', '%dx%d' % (initial_w, initial_h), # size of image string\n",
    "                 '-pixel_format' ,  'bgr24', # format\n",
    "                 '-f', 'rawvideo',  '-i', '-', # tell ffmpeg to expect raw video from the pipe\n",
    "                 'http://localhost:8090/fac.ffm') # output encoding\n",
    "    p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE)\n",
    "    while cap.isOpened():\n",
    "        flag, frame = cap.read()\n",
    "        if not flag:\n",
    "            break\n",
    "        key_pressed = cv2.waitKey(1)\n",
    "        # Start async inference\n",
    "        image = cv2.resize(frame, (w, h))\n",
    "        # Change data layout from HWC to CHW\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "        # Start asynchronous inference for specified request.\n",
    "        inf_start = time.time()\n",
    "        infer_network.exec_net(cur_request_id, image)\n",
    "        # Wait for the result\n",
    "        if infer_network.wait(cur_request_id) == 0:\n",
    "            det_time = time.time() - inf_start\n",
    "            # Results of the output layer of the network\n",
    "            result = infer_network.get_output(cur_request_id)\n",
    "\n",
    "            if os.environ['PERF_COUNTS'] == True:\n",
    "                perf_count = infer_network.performance_counter(cur_request_id)\n",
    "                performance_counts(perf_count)\n",
    "\n",
    "            frame, current_count = ssd_out(frame, result)\n",
    "            inf_time_message = \"Inference time: {:.3f}ms\"\\\n",
    "                               .format(det_time * 1000)\n",
    "            cv2.putText(frame, inf_time_message, (15, 15),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 0.5, (200, 10, 10), 1)\n",
    "\n",
    "            # When new person enters the video\n",
    "            if current_count > last_count:\n",
    "                start_time = time.time()\n",
    "                total_count = total_count + current_count - last_count\n",
    "#                client.publish(\"person\", json.dumps({\"total\": total_count}))\n",
    "\n",
    "            # Person duration in the video is calculated\n",
    "            if current_count < last_count:\n",
    "                duration = int(time.time() - start_time)\n",
    "                # Publish messages to the MQTT server\n",
    "                client.publish(\"person/duration\",\n",
    "                               json.dumps({\"duration\": duration}))\n",
    "\n",
    "            client.publish(\"person\", json.dumps({\"count\": current_count}))\n",
    "            last_count = current_count\n",
    "\n",
    "            if key_pressed == 27:\n",
    "                break\n",
    "\n",
    "        # Send frame to the ffmpeg server\n",
    "\n",
    "        p.stdin.write(frame.tobytes())\n",
    "        if single_image_mode:\n",
    "            cv2.imwrite('output_image.jpg', frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    client.disconnect()\n",
    "    infer_network.clean()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
